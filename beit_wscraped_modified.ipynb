{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from jutils import open_img_id, img_exists, SquarePad, onehot, labelstring\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "import torchvision.transforms.functional as fn\n",
    "\n",
    "\n",
    "from transformers import BeitFeatureExtractor, BeitForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n",
    "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n",
    "\n",
    "\n",
    "# read in images\n",
    "padder = SquarePad()\n",
    "df = pd.read_csv('train_Kea.csv')\n",
    "# throw away missing images\n",
    "df = df.loc[df.image_id.apply(img_exists)]\n",
    "df['Images'] = df['image_id'].apply(open_img_id).apply(padder)\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as fn\n",
    "transforms = [\n",
    "    fn.hflip,\n",
    "    T.Compose([T.GaussianBlur(9)]),\n",
    "    T.Compose([fn.hflip, T.GaussianBlur(9)]),\n",
    "    T.Compose([fn.hflip, T.RandomAdjustSharpness(0.1, p=1)]),\n",
    "    fn.vflip,\n",
    "    T.Compose([fn.vflip, T.GaussianBlur(9)]),\n",
    "    T.Compose([fn.vflip, T.RandomAdjustSharpness(0.1, p=1)]),\n",
    "]\n",
    "augmented = []\n",
    "\n",
    "for t in transforms:\n",
    "    df2 = df.copy()\n",
    "    df2['Images'] = df2['Images'].apply(t)\n",
    "    augmented.append(df2)\n",
    "\n",
    "df = pd.concat([df]+augmented)\n",
    "\n",
    "labelsdf = pd.read_csv('labels.csv')\n",
    "labels = labelsdf['object'].values.tolist()\n",
    "y_train = np.array([ onehot(lbl) for lbl in df['labels'] ]).astype(int)\n",
    "inputs = feature_extractor(images=df['Images'].tolist(), return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "X_train = outputs['logits']\n",
    "logres = LogisticRegression(dual=True, solver='liblinear', random_state=342985, max_iter=400, class_weight='balanced')\n",
    "final = ClassifierChain(logres)\n",
    "final.fit(X_train, y_train) #logistic regression\n",
    "\n",
    "\n",
    "testdf = pd.read_csv('test.csv')\n",
    "testlabels = []\n",
    "labelsdf = pd.read_csv('labels.csv')\n",
    "for img_id in testdf.image_id:\n",
    "    try:\n",
    "        inputs = feature_extractor([open_img_id(img_id)], return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            x = model(**inputs)\n",
    "        prediction = final.predict(x['logits'])\n",
    "        predicted_labels = labelstring(prediction.astype(bool))\n",
    "\n",
    "        if len(predicted_labels) == 0:\n",
    "            testlabels.append('l1')\n",
    "        else:\n",
    "            testlabels.append(predicted_labels)\n",
    "        print(img_id,\n",
    "              ' '.join(labelsdf.loc[labelsdf.label_id.isin(testlabels[-1].split(' ')), 'object'].values.ravel()),\n",
    "              sep='\\t')\n",
    "    except FileNotFoundError:\n",
    "        print(img_id, 'missing, defaulting to l0')\n",
    "        testlabels.append('l0')\n",
    "\n",
    "testdf['labels'] = testlabels\n",
    "testdf.to_csv('joosep_submissions/kea_beit_wscraped_modified.csv', index=False) # Test mfscore 0.56\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('atm_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f182084b941899f81698fb3b740c7166625a3245e0fe4789d0140e51bdb253f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}