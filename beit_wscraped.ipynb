{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random_clip_forest\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import torchvision.transforms.functional as fn\n",
    "from torchvision.transforms import RandomAffine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BeitFeatureExtractor, BeitForImageClassification\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n",
    "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images\n",
    "df = pd.read_csv('train_Kea.csv')\n",
    "# throw away missing images\n",
    "df = df.loc[df.image_id.apply(random_clip_forest.img_exists)]\n",
    "df['Images'] = df['image_id'].apply(random_clip_forest.open_img_id)\n",
    "\n",
    "df2 = df.copy()\n",
    "df2['Images'] = df['Images'].apply(fn.hflip)\n",
    "\n",
    "df3 = df.copy()\n",
    "df3['Images'] = [fn.gaussian_blur(img=image,kernel_size=(9,9)) for image in df['Images']]\n",
    "\n",
    "df = pd.concat([df, df2, df3])\n",
    "\n",
    "labelsdf = pd.read_csv('labels.csv')\n",
    "labels = labelsdf['object'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([\n",
    "    random_clip_forest.onehot(lbl) for lbl in df['labels']\n",
    "]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = feature_extractor(images=df['Images'].tolist(), return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = outputs['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Logistic regression #########\n",
    "logres = LogisticRegression(dual=True, solver='liblinear', random_state=342985, max_iter=400, class_weight='balanced')\n",
    "final = MultiOutputClassifier(logres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kohvk\\anaconda3\\envs\\atm_2022\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                   dual=True, max_iter=400,\n",
       "                                                   random_state=342985,\n",
       "                                                   solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                   dual=True, max_iter=400,\n",
       "                                                   random_state=342985,\n",
       "                                                   solver=&#x27;liblinear&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, dual=True, max_iter=400,\n",
       "                   random_state=342985, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, dual=True, max_iter=400,\n",
       "                   random_state=342985, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   dual=True, max_iter=400,\n",
       "                                                   random_state=342985,\n",
       "                                                   solver='liblinear'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.fit(X_train, y_train) #logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img102.jpg\tpeople trees buildings town hall of tartu estonian flag flags drone photography\n",
      "img103.jpg\ttrees grass nature sign\n",
      "img11.jpg\tpeople snow man\n",
      "img113.jpg\tgrass nature sunny plants\n",
      "img114.jpg\tflowers\n",
      "img121.jpg\tpeople trees grass water sand playground lamp post beach\n",
      "img126.jpg\tpeople water\n",
      "img131.jpg\tpeople person hands table\n",
      "img136.jpg\tpeople\n",
      "img137.jpg\ttrees snow\n",
      "img139.jpg\ttrees snow\n",
      "img140.jpg\ttrees sand outdoor gym\n",
      "img15.jpg\tgreen garbage can\n",
      "img150.jpg\ttraffic signs\n",
      "img151.jpg\tbuildings road cars traffic signs\n",
      "img152.jpg\tpeople buildings road traffic signs\n",
      "img156.jpg\ttrees road bicycle\n",
      "img161.jpg\tpeople trees water barge emajõe-peipsi barge jõmmu\n",
      "img166.jpg\ttrees grass building person pavement crosswalk\n",
      "img167.jpg\tgrass road\n",
      "img170.jpg\tpeople trees building stone road table\n",
      "img173.jpg\ttrees snow\n",
      "img176.jpg\tpeople trees snow buildings stroller\n",
      "img18.jpg\ttrees green garbage can\n",
      "img180.jpg\tpeople trees buildings bench\n",
      "img181.jpg\ttrees grass building nature bicycle\n",
      "img182.jpg\tpeople trees building road\n",
      "img183.jpg\ttrees grass bridge\n",
      "img189.jpg\ttrees buildings water bridge\n",
      "img192.jpg\tpeople trees grass bicycle pavement\n",
      "img194.jpg\tpeople grass\n",
      "img195.jpg\tpeople grass sand bench playground children\n",
      "img206.jpg\tpeople trees grass buildings pavement\n",
      "img208.jpg\tgrass buildings flowers\n",
      "img209.jpg\tpeople trees grass nature\n",
      "img211.jpg\ttrees buildings lamp posts\n",
      "img212.jpg\ttrees grass\n",
      "img218.jpg\tperson bench leaves man book\n",
      "img22.jpg\ttrees grass stairs stone road stair railings\n",
      "img221.jpg\tbuilding buildings water estonian flag the sculpture of kissing students\n",
      "img228.jpg\ttrees snow road winter tractor snow plow\n",
      "img230.jpg\ttrees snow snow plow\n",
      "img231.jpg\tsnow road winter snow plow\n",
      "img234.jpg\ttrees building snow buildings cars tractor\n",
      "img238.jpg\tpeople bicycle\n",
      "img243.jpg\tpeople grass buildings water\n",
      "img247.jpg\ttrees grass buildings water nature\n",
      "img248.jpg\tgraffiti wall\n",
      "img249.jpg\ttrees\n",
      "img250.jpg\tgraffiti\n",
      "img251.jpg\ttrees grass bicycle pavement\n",
      "img252.jpg\tbicycle graffiti wall\n",
      "img257.jpg\ttrees flowers\n",
      "img259.jpg\tbuilding\n",
      "img262.jpg\ttrees\n",
      "img265.jpg\tbooks\n",
      "img266.jpg\ttrees cars\n",
      "img279.jpg\tpeople buildings water barge emajõe-peipsi barge jõmmu\n",
      "img280.jpg\tpeople buildings\n",
      "img281.jpg\ttown hall of tartu\n",
      "img285.jpg missing, defaulting to l0\n",
      "img288.jpg missing, defaulting to l0\n",
      "img292.jpg\tpeople building buildings\n",
      "img296.jpg\tbuilding town hall of tartu estonian flag the sculpture of kissing students fountain\n",
      "img3.jpg\tpeople building snow road winter tree suitcase flag\n",
      "img300.jpg\tbuilding water the sculpture of kissing students fountain\n",
      "img33.jpg\tpeople trees\n",
      "img37.jpg\ttrees\n",
      "img39.jpg\ttrees\n",
      "img41.jpg\tperson bicycle pavement traffic sign crosswalk\n",
      "img42.jpg\tpeople traffic signs\n",
      "img43.jpg\tbuildings\n",
      "img48.jpg\tpeople building road cars traffic sign cloudy traffic\n",
      "img49.jpg\tpeople person crosswalk\n",
      "img5.jpg\tpeople snow winter tree worker plane cone\n",
      "img57.jpg\tsunny\n",
      "img59.jpg\troad cars\n",
      "img69.jpg\tpeople trees drone photography tents\n",
      "img71.jpg\tpeople\n",
      "img73.jpg\tpeople performing\n",
      "img75.jpg\tpeople performing\n",
      "img79.jpg\tgrass\n",
      "img8.jpg\tpeople building cars\n",
      "img81.jpg\tgrass\n",
      "img84.jpg\tflowers wedding hands\n",
      "img90.jpg\tpeople estonian flag child\n",
      "img93.jpg\ttrees flowers\n",
      "img94.jpg\tflowers\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('test.csv')\n",
    "testlabels = []\n",
    "labelsdf = pd.read_csv('labels.csv')\n",
    "for img_id in testdf.image_id:\n",
    "    try:\n",
    "        inputs = feature_extractor([random_clip_forest.open_img_id(img_id)], return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            x = model(**inputs)\n",
    "        prediction = final.predict(x['logits'])\n",
    "        predicted_labels = random_clip_forest.labelstring(prediction.astype(bool))\n",
    "\n",
    "        if len(predicted_labels) == 0:\n",
    "            testlabels.append('l1')\n",
    "        else:\n",
    "            testlabels.append(predicted_labels)\n",
    "        print(img_id,\n",
    "                ' '.join(labelsdf.loc[labelsdf.label_id.isin(testlabels[-1].split(' ')), 'object'].values.ravel()),\n",
    "                sep='\\t')\n",
    "    except FileNotFoundError:\n",
    "        print(img_id, 'missing, defaulting to l0')\n",
    "        testlabels.append('l0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['labels'] = testlabels\n",
    "testdf.to_csv('kea_submissions/beit_logreg_wscraped_vers2.csv', index=False) # Test mfscore ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('lavis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93246883c1c59bdc92d575674c89e457f8fbeb3e211cb28836301b37184d8a2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
